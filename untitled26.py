# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16HPka1bJud5opRjg4U0NC678YciB7EDg
"""

from google.colab import drive
drive.mount('/content/drive')

import os, pathlib, shutil
import numpy as np
import matplotlib.pyplot as plt
import itertools
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, applications

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
SEED = 42
AUTOTUNE = tf.data.AUTOTUNE

TRAIN_DIR = "/content/drive/MyDrive/bird_drone_project/classification_dataset/train-20251113T160913Z-1-001/train"
VALID_DIR = "/content/drive/MyDrive/bird_drone_project/classification_dataset/valid-20251113T160916Z-1-001/valid"
TEST_DIR  = "/content/drive/MyDrive/bird_drone_project/classification_dataset/test-20251113T154837Z-1-001/test"

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    TRAIN_DIR,
    label_mode='binary',
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=42,
    shuffle=True
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    VALID_DIR,
    label_mode='binary',
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=42,
    shuffle=False
)

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    TEST_DIR,
    label_mode='binary',
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=42,
    shuffle=False
)

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.12),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
    layers.RandomTranslation(0.05, 0.05)
], name='data_augmentation')

def build_custom_cnn(input_shape=IMG_SIZE + (3,)):
    inputs = layers.Input(shape=input_shape)

    x = data_augmentation(inputs)
    x = layers.Rescaling(1./255)(x)

    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.4)(x)

    x = layers.Dense(64, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)

    outputs = layers.Dense(1, activation='sigmoid')(x)


    model = models.Model(inputs=inputs, outputs=outputs)

    return model

custom_model = build_custom_cnn()
custom_model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

callbacks = [
    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),
    ModelCheckpoint("/content/best_custom_cnn.h5", monitor='val_loss', save_best_only=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
]

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
callbacks_cnn = [
    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),
    ModelCheckpoint("best_cnn_model.h5", monitor='val_loss', save_best_only=True)
]

custom_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

EPOCHS = 12

history_cnn = custom_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks_cnn
)

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history_cnn.history['accuracy'])
plt.plot(history_cnn.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.show()

plt.plot(history_cnn.history['loss'])
plt.plot(history_cnn.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

model_tl.save("/content/best_model.keras")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Training data generator with augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# Validation data generator (just rescale)
valid_datagen = ImageDataGenerator(rescale=1./255)

# Load training data
train = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/bird_drone_project/classification_dataset/train-20251113T160913Z-1-001/train',   # change to your training folder path
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Load validation data
valid = valid_datagen.flow_from_directory(
    '/content/drive/MyDrive/bird_drone_project/classification_dataset/valid-20251113T160916Z-1-001/valid',   # change to your validation folder path
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

y_pred = custom_model.predict(test_ds)
y_pred = (y_pred > 0.5).astype(int)

!ls -R /content/drive/MyDrive
!ls -R /content/drive/MyDrive/bird_drone_project

from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model

# Load base model
base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet'
)

base_model.trainable = False   # freeze weights

# Add custom layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
outputs = Dense(2, activation='softmax')(x)   # For 2 classes

model_tl = Model(inputs=base_model.input, outputs=outputs)

# Compile
model_tl.compile(
    optimizer='adam',
    loss='categorical_crossentropy',   # Because 2 classes
    metrics=['accuracy']
)

history_tl = model_tl.fit(
    train,
    validation_data=valid,
    epochs=10
)

test_datagen = ImageDataGenerator(rescale=1./255)

test = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/bird_drone_project/classification_dataset/test-20251113T154837Z-1-001/test',          # <-- change to your actual test folder
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False              # IMPORTANT for correct predictions
)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# Predictions
t_predictions = model_tl.predict(test)
y_pred = np.argmax(t_predictions, axis=1)
y_true = test.classes

# Reports
print(confusion_matrix(y_true, y_pred))
print(classification_report(y_true, y_pred))

t_predictions = model_tl.predict(test)

# Convert softmax probabilities to class labels
y_pred = np.argmax(t_predictions, axis=1)
y_true = test.classes

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(y_true, y_pred))
print(classification_report(y_true, y_pred, target_names=["Bird", "Drone"]))

t_predictions = model_tl.predict(test)

# Convert softmax probabilities to class labels
y_pred = np.argmax(t_predictions, axis=1)
y_true = test.classes

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(y_true, y_pred))
print(classification_report(y_true, y_pred, target_names=["Bird", "Drone"]))

model_tl.save("bird_drone_transfer_model.h5")

!ls "/content/drive/MyDrive/bird_drone_project/classification_dataset/train-20251113T160913Z-1-001/train"

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

bird_path = "/content/drive/MyDrive/bird_drone_project/classification_dataset/test-20251113T154837Z-1-001/test/bird"
img_name = os.listdir(bird_path)[0]
img = mpimg.imread(os.path.join(bird_path, img_name))

plt.imshow(img)
plt.title("Bird Sample")
plt.axis('off')

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

drone_path = "/content/drive/MyDrive/bird_drone_project/classification_dataset/test-20251113T154837Z-1-001/test/drone"
img_name = os.listdir(drone_path)[0]
img = mpimg.imread(os.path.join(drone_path, img_name))

plt.imshow(img)
plt.title("Drone Sample")
plt.axis('off')

model_tl.save("final_bird_drone_model.h5")

!npm install -g localtunnel

!pip install streamlit tensorflow pillow numpy

# install streamlit
!pip install streamlit pyngrok

!pip install ultralytics

# Token Add
!ngrok config add-authtoken "34pBZArucIzwiqZA2y1JZjVBDBj_2o3vCZUEdbHzeuW5h9nfi"

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_advanced.py
# import streamlit as st
# from PIL import Image
# import numpy as np
# import tensorflow as tf
# 
# st.set_page_config(page_title="Bird & Drone Detector", layout="wide")
# st.title("ðŸ¦… Bird & Drone Classification ")
# 
# # Load Keras model
# MODEL_PATH = "/content/bird_drone_transfer_model.h5"
# 
# try:
#     model = tf.keras.models.load_model(MODEL_PATH)
#     st.success("Model Loaded Successfully!")
# except Exception as e:
#     st.error(f"Model Load Error: {e}")
# 
# # Upload image
# uploaded_file = st.file_uploader("Upload an Image", type=["jpg", "png", "jpeg"])
# 
# def preprocess(img):
#     img = img.resize((224, 224))        # same size as training
#     img = np.array(img) / 255.0        # normalize
#     img = np.expand_dims(img, axis=0)  # batch dimension
#     return img
# 
# if uploaded_file:
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Uploaded Image", use_container_width=True)
# 
#     if st.button("Run Detection"):
#         img_prep = preprocess(image)
# 
#         preds = model.predict(img_prep)[0]
# 
#         bird_prob = preds[0]
#         drone_prob = preds[1]
# 
#         label = "Bird" if bird_prob > drone_prob else "Drone"
#         accuracy = max(bird_prob, drone_prob) * 100
# 
#         # COUNT -> 1 image = 1 object
#         bird_count = 1 if label == "Bird" else 0
#         drone_count = 1 if label == "Drone" else 0
# 
#         st.subheader("ðŸ“Š Detection Summary")
#         st.write(f"**Prediction:** {label}")
#         st.write(f"**Bird Count:** {bird_count}")
#         st.write(f"**Drone Count:** {drone_count}")
#         st.write(f"**Accuracy:** {accuracy:.2f}%")
#

!nohup streamlit run app.py --server.port 8501 &
ngrok.connect(8501)